# CUDA High-Performance Local Binary Patterns (LBP)

This repository contains a high-performance parallel implementation of the **Local Binary Patterns (LBP)** operator using **NVIDIA CUDA**. 
The project demonstrates the evolution from a sequential CPU algorithm to a highly optimized GPU pipeline capable of real-time video processing throughput.

## üìå Problem Description
Local Binary Patterns (LBP) is a powerful texture descriptor used in Computer Vision (e.g., face recognition, texture classification). For each pixel in an image, the algorithm compares the center pixel with its $3 \times 3$ neighbors, generating an 8-bit binary code.

While computationally simple, applying LBP to high-resolution video streams in real-time requires massive bandwidth and parallelism. This project solves the bottleneck by leveraging the GPU's SIMT architecture and optimizing memory access patterns.

### üñºÔ∏è Visual Example

<table>
<tr>
<td><b>Input Image</b></td>
<td><b>LBP Output</b></td>
</tr>
<tr>
<td><img src="input.jpg" width="400" alt="Input Image"/></td>
<td><img src="output_cuda.png" width="400" alt="LBP Output"/></td>
</tr>
</table>

The LBP algorithm transforms the input image into a texture descriptor where each pixel encodes the local pattern of its neighborhood, useful for texture analysis and feature extraction.

## üöÄ Key Optimizations
The implementation explores several optimization strategies:
1.  **Naive Implementation:** Direct mapping of threads to pixels using Global Memory.
2.  **Shared Memory:** Reducing global memory traffic by caching thread blocks and halos (though limited by synchronization overhead).
3.  **Read-Only Cache (`__ldg`):** Utilizing the Texture/L1 cache path to handle spatial locality and unaligned accesses efficiently.
4.  **CUDA Streams (Batch Processing):** An asynchronous pipeline that overlaps Compute and Data Transfer (PCIe), effectively maximizing system throughput (~10.6 GB/s).

## üìÇ File Structure

### Core Implementation Files
* **`sequential.cpp`**: Sequential CPU implementation of LBP with both single-threaded and OpenMP parallel versions for performance baseline comparison.
* **`parallel_base.cu`**: Naive GPU implementation using global memory. Direct thread-to-pixel mapping serving as the baseline CUDA implementation.
* **`parallel_shared.cu`**: Optimized GPU implementation using shared memory with halo loading to reduce global memory traffic.
* **`parallel_texture.cu`**: GPU implementation utilizing read-only cache (`__ldg` intrinsic) for improved memory access patterns and caching.
* **`parallel_stream.cu`**: Advanced GPU implementation with CUDA streams for asynchronous batch processing, overlapping compute and data transfer to maximize PCIe bandwidth utilization. It uses the read-only cache optimization.
* **`parallel_stream_naive.cu`**: A variant of the stream-based implementation with global memory usage.

### Build and Testing Files
* **`CMakeLists.txt`**: CMake build configuration for compiling all CPU and GPU executables with proper CUDA architecture settings.
* **`benchmark.sh`**: Automated benchmarking script that runs all implementations with different configurations (block sizes, stream counts) and collects performance metrics into CSV format.
* **`plots.py`**: Python script for generating performance visualization plots comparing CPU vs GPU, tuning parameters, and scalability metrics from benchmark results.

### Assets and Results
* **`stb_image.h` / `stb_image_write.h`**: Single-header libraries for loading and saving images without external dependencies like OpenCV.
* **`input.jpg`**: Sample high-resolution image used for benchmarking all implementations.
* **`results_final.csv`**: Performance benchmark results including execution times and bandwidth measurements.
* **`output_cuda.png`**: Output images generated by different implementations for correctness validation.
* **`plot_*.png`**: Generated performance comparison charts (CPU vs GPU, parameter tuning, scalability analysis).

## üõ† Requirements

To build and run this project, you need:

* **Hardware:** NVIDIA GPU (Compute Capability 3.0 or higher).
* **Software:**
    * NVIDIA CUDA Toolkit (NVCC compiler).
    * GCC/G++ compiler.
    * Linux environment (recommended for the bash script).

## ‚ö° How to Build and Run

### 1. Compilation
The project uses CMake for building all executables. The build system automatically detects your GPU architecture or you can specify it manually.

```bash
# Create build directory
mkdir -p cmake-build-debug
cd cmake-build-debug

# Configure and build (auto-detects GPU architecture)
cmake ..
cmake --build .

# Or specify GPU architecture manually:
# cmake -DCMAKE_CUDA_ARCHITECTURES=61 ..
# Replace '61' with your GPU compute capability (e.g., 75 for Turing, 86 for Ampere)
```

This will generate the following executables:
- `LBP_Sequential` - CPU implementations
- `Parallel_Base` - Naive GPU with global memory
- `Parallel_Shared` - GPU with shared memory optimization
- `Parallel_Texture` - GPU with read-only cache optimization
- `Parallel_streams` - GPU with CUDA streams for batch processing
- `Parallel_streams_naive` - Stream-based GPU with global memory

### 2. Running Benchmarks
The `benchmark.sh` script automates the testing process, running all implementations with different configurations and collecting performance metrics.

**Steps:**
1. Make the script executable:
   ```bash
   chmod +x benchmark.sh
   ```
2. Run the benchmark:
   ```bash
   ./benchmark.sh
   ```

The script will execute all implementations multiple times (default: 5 runs per configuration) with varying block sizes and parameters, outputting results to `results_final.csv` with execution times and effective bandwidth (GB/s).

### 3. Visualizing Results
Generate performance comparison plots from the benchmark data:
```bash
python3 plots.py
```

This creates three visualization charts:
- CPU vs GPU performance comparison
- Parameter tuning analysis
- Scalability metrics
---
##üìä Performance Results
On a reference NVIDIA GTX 1050 (Pascal), this implementation achieved:
* Speedup: ~284x vs Sequential CPU.
* Throughput: ~10.6 GB/s, effectively saturating the PCIe bandwidth using asynchronous batch processing with read only memory approach.


